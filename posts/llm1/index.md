# LLM系列1：LLM前的NLP基础


本文对LLM前的基于DL的NLP算法做了一个回顾。对word2vec和seq2seq， 并对attention、Transformer和BERT等知识做了一个较为深入浅出的介绍，希望对读者有益。

本文的目录如下：
* 概述
* word2vec
* seq2seq
* Attention 与 Transformer
* BERT系列


[pdf文件](/posts/ml/llm1/llm1.pdf)


---

> Author: jianjun wu  
> URL: https://valwu.gitee.io/posts/llm1/  

