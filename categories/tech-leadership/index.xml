<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Tech Leadership - Category - KnowledgeSqueezer</title>
    <link>https://valwu.gitee.io/categories/tech-leadership/</link>
    <description>Tech Leadership - Category | KnowledgeSqueezer</description>
    <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Sat, 02 Mar 2024 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://valwu.gitee.io/categories/tech-leadership/" rel="self" type="application/rss+xml" /><item>
  <title>算法项目失败的100种原因</title>
  <link>https://valwu.gitee.io/posts/algomanage/</link>
  <pubDate>Sat, 02 Mar 2024 00:00:00 &#43;0000</pubDate>
  <author>Author</author>
  <guid>https://valwu.gitee.io/posts/algomanage/</guid>
  <description><![CDATA[笔者经历过不少算法项目，如今回顾起来，感觉要做好算法项目殊为不易。有些点对一部分人显而易见，但是对别人可能难以理解甚至无法实现。 即便算法项目取得成功的难度其实很大，但是为了实现数据价值给予公司业务强大的赋能，笔者与读者共勉。
背景概述对于90%的公司来说，算法项目有几个特点：
投入比较大，甚至是很大的，无论是人力，时间还是金钱。 很多模型要做3个月，6个月，甚至数年。 要找合适的人，要买服务器，高阶算法要买GPU。 等等。 对公司/团队的IT基建，研发能力，数据质量等方面有不算很低的要求。 能方便地查阅全世界最新的论文。 能够导出合规的数据到训练集群。 核心数据要完整且正确。 能够处理海量数据，能够完成海量复杂计算，能够稳健地应对高并发访问。 等等。 对参与人员的思维认知等方面可能会构成不算很微小的挑战。 不知道模型需要训练， 不知道如何验收模型， 以为模型万能，不万能就是零分。 以为一句几句话丢出去，就会有个牛逼的模型飞回来。 等等 相对来说是复杂的，甚至是很复杂的，涉及的技术面非常高，涉及到的协作方也可能很多。 可能涉及的角色包括，业务专家，数据开发，数据挖掘，算法开发，系统架构师，系统开发，前端开发，数据分析等 可能涉及到的编程语言包括，SQL，scala，python，c++，java，go等。 涉及到的输入数据种类可能包括，表格数据，集合数据，序列数据，lbs数据，文本数据，图片数据，甚至是语音和视频数据。 比起系统开发和数据开发，算法项目的过程和结果都存在更明显的不确定性和探索性。 能不能挖掘出有效的预测因子?? 能不能选择正确的算法路线??万一你熟悉的算法不work，怎么办???你不可能熟悉所有算法。 模型训练完毕前，你很难准确预估auc，准确率，召回率等。 流量实验完毕前，你很难预估各个业务指标的改进幅度。 一个算法，别的地方可能效果非常好，到了公司业务场景可能效果就不好了。&ndash;当然可能是论文作者说瞎话，也可能是人家的数据集更好。 算法项目失败的100种原因需求不可行 应用场景不明确或者反复变化： 比如一开始要一个推荐模型，后来说要给每个品类都做一个推荐模型。 应用场景不可行或者算法不可能有效： 比如研发一个可以比肩专业红娘的AI，来谈恋爱，解决情感困难、兜售会员服务，电话推销等。对99%的公司来说，目前的AI发展水平还没到这个程度，最顶尖的公司或许可以做到。 比如研发一个根据用户人脸照片来判断疾病种类的模型。人类医生一般都不准，此时模型也不会准，不要以为算法可以超越专业人类。 比如商品推荐列表，但是用户第一眼看到的都是很相似的商品缩略图，此时推荐结果是无用的。 无法获取足够的高质量的可学习的标注数据： 比如腾讯团队预测其用户会不会买拼多多某些商品。 &ndash; 腾讯是拿不到拼多多站内用户是否购买的数据。 比如研发一个模型去给用户打信用分，信用分之前是用规则打的，给到的样本全都规则打的分，这种情况下训练模型没有意义。&ndash;模型此时就是学习这些规则，既然如此干嘛不直接用规则呢??? 如果分不准确，那么哪里有准确的分呢???没有准确的分，模型怎么学习??? 比如研发一个模型去给用户打薅羊毛分，但是没办法定义什么叫薅羊毛什么叫没薅羊毛。 &ndash; 虽然这个模型做出来很有用，但是模型的训练数据哪里有呢???哪里有薅羊毛分??? 比如风控场景中，用户在短时间内呈现出矛盾的判断，好坏坏好/坏好坏好好，但是给到的标注数据却是按天的，同时要求模型实时判定。 标注数据与应用场景对不上，这个问题对于那些手工维护的标注数据特别容易发生： 比如希望预测销售员入职一年后是否留存，但是系统中只能拿到三个月是否留存的数据。 比如标注了一波坏人，但是不知道这波人什么时间变坏的(标注时间没到天、更没到秒)。应用场景却要求给定模型秒级响应、给定一个人模型实时判定这个人到这一秒是不是坏人(因为人可能在某一分钟采取某个行为从而被认定是坏的)。&ndash; 模型要用在什么场景，那么就要有这个场景下的标注数据。 无法获取足够丰富有效的入模特征： 比如中小型公司预测其某个广告在抖音投放后的ROI。&ndash; 抖音没有将目标用户的效果转化数据及时完整地回传，并且目标用户的行为属性全部在抖音上。中小型公司无法获得。 数据或者系统不可行 业务系统没有记录关键数据 比如要预测用户是否购买某个产品，但是以往的只有查看后购买记录，却没有查看后未购买的记录。 比如要预测用户是否会投诉，虽然保留了过去一段时间内用户投诉记录，但是却只保留了用户最新的状态/画像，没办法获取历史投诉记录在投诉那一刻的状态/画像。 比如要计算快递员和送货地址之间的实时距离，但是系统却没有记录快递员的实时经纬度，或者没有将这个数据全量落库。 比如要根据用户的行为实时更新推荐列表，比如根据用户是否喜欢第一个视频来更新第二个视频的内容，但是却没有及时上报第一个视频是否喜欢。 比如研发客服AI时，系统没有记录以往的QA对儿。 业务系统记录的数据质量低下或者难以使用。 比如研发客服AI时，业务知识库全靠客服人员口述，这样就需要花费很大精力来整理业务知识。 比如研发客服AI时，系统记录的以往的QA对儿存在大量错别字，隐喻，黑话，术语，表意晦涩难懂。还可能以往的answer可能不符合业务规范、甚至胡乱回答。 比如研发客服AI时，系统记录的以往的QA对儿是语音。 平台系统无法做模型训练 比如大数据平台的数据不准离开大数据集群，模型训练平台却在大数据集群外。 比如大数据平台的版本太老或者太封闭，无法运行或者安装某些算法包。 比如运维不允许SSH到训练模型的服务器。 比如运维不给服务器的root权限，导致无法安装一些复杂的算法包。&ndash;同时运维又安装不来。 比如服务器驱动版本太低或者内核版本太低，无法运行一些新的算法包。 比如服务器缺乏一些关键的功能，比如gcc /cmake/yum，导致安装不了很多算法包。 比如服务器不允许访问外网，导致无法下载外网的一些模型库。&ndash;不得不手动下载上传，耗时巨大。 比如没有高性能服务器(内存小/cpu少/磁盘小/没有gpu)或者分布式集群，导致一些大型模型训练无法进行。 研发人员能力不足 算法人员能力不足 比如算法人员采用在工业界公认很不恰当的算法，如knn，k-means、pca，linear regression等。&ndash;容易发生在刚入行的人身上。 比如算法人员采用无法生产落地的语言或者框架，比如采用spark训练模型却要求用go语言上线部署，或者采用tensorflow 1.]]></description>
</item>
</channel>
</rss>
